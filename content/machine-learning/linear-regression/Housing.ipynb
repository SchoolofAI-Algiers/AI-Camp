{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67f5ad5-0724-4eac-8fe2-2c916f7f3486",
   "metadata": {},
   "source": [
    "## 1.Importing Data To .CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f5991b-44ef-45b2-9e32-2b41d583a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    " os.makedirs(housing_path, exist_ok=True)\n",
    " tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    " urllib.request.urlretrieve(housing_url, tgz_path)\n",
    " housing_tgz = tarfile.open(tgz_path)\n",
    " housing_tgz.extractall(path=housing_path)\n",
    " housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2a555-6a90-429b-9d8d-2a8d405af7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    " csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    " return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ed030-f21a-4270-b40f-8a67680c2b0d",
   "metadata": {},
   "source": [
    "## 2.Analyzing the data\n",
    "let's first import our data and have a quick look at the first 5 columns using head method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8e1c4-7a5b-4461-8ed4-9e62532efc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data() #fetching data\n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7710fb1e-91b3-488c-9009-c6aa201e85ef",
   "metadata": {},
   "source": [
    "Now let's see infos about our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ba7cc-be98-4e43-b222-4556df2d1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbafd968-0b71-4c1d-ab9c-b67216bc785d",
   "metadata": {},
   "source": [
    "We remarque that some columns contain non numerical values such as ocean_proximity , let's have a look at how many values does this column may contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68661e2-08d3-461f-8d0d-56a892c3ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d6bdd-ae57-4f8e-a9ac-e015c359a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c48771-d105-4cbe-aa33-b5e868fb6ea0",
   "metadata": {},
   "source": [
    "Another way to analyze the data is by plotting into histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161c012-cbac-4184-961b-783cd5f6a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27211c27-d312-4720-9190-eae0ac4c2e08",
   "metadata": {},
   "source": [
    "## 3.Creating The test set \n",
    "Now we need to create a test set , so we will build a function that splits our data into a train set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b79843-9520-40ff-866c-1054830e6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda083c-8d60-4363-b9b7-b1595a812f22",
   "metadata": {},
   "source": [
    "## 4.Looking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c87122-3760-433b-9bd7-9e35572cd54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083b9cb-3551-4fbb-8c3a-1cec6b44953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f39f5-6ea0-4f0b-9f44-d1d60fbbe988",
   "metadata": {},
   "source": [
    "If correlation is close to 1 , it means if a y goes up the, x also goes up , -1 is the opposite and for 0 there is no linear relation between y and x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf28fb-8bb3-426c-a975-17d6d7ccf9fa",
   "metadata": {},
   "source": [
    "Another way to check for correlation between attributes is to use the pandas\n",
    "scatter_matrix() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98563b-95e0-462e-8567-1f6e2d754751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    " \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e027d861-3b7d-4754-bb3c-16cb95f497de",
   "metadata": {},
   "source": [
    "The most promising attribute to predict the median house value is the median\n",
    "income, so let’s zoom in on their correlation scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ecebdc-83b5-489a-a910-0484081dbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
    " alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20204ec-9213-4423-8af0-99d869e75390",
   "metadata": {},
   "source": [
    "This plot reveals a few things. First, the correlation is indeed very strong; you can\n",
    "clearly see the upward trend, and the points are not too dispersed. Second, the price\n",
    "cap that we noticed earlier is clearly visible as a horizontal line a $500,000. But this\n",
    "plot reveals other less obvious straight lines: a horizontal line aroud $450,000,\n",
    "another aro3d $350,000, perhaps one around $280,000, and a few more below that.\n",
    "You may want to try removing the corresponding districts to prevent your algorithms\n",
    "from learning to reproduce these data quirks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb1c83-e3c0-43a5-ba0f-06c7f602ed12",
   "metadata": {},
   "source": [
    "Since Now we analyzed the data , we may create some attributes that may be more interesting for our case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f26b0-0b3e-49cb-a3eb-1f627b020a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0dc60-4e7c-468c-9e64-a7609baa4474",
   "metadata": {},
   "source": [
    "Now let's see their correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7659efb-82fc-4260-8c16-5f188fa60e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d9373-2d65-4bf8-93df-b649da28440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a1fc0-8e9a-48b1-a9ec-67bcbfe101df",
   "metadata": {},
   "source": [
    "Hey, not bad! The new bedrooms_per_room attribute is much more correlated with\n",
    "the median house value than the total number of rooms or bedrooms. Apparently\n",
    "houses with a lower bedroom/room ratio tend to be more expensive. The number of\n",
    "rooms per household is also more informative than the total number of rooms in a\n",
    "district—obviously the larger the houses, the more expensive they ar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2abf14f-140a-450d-9688-ca6811cb2afa",
   "metadata": {},
   "source": [
    "## Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf41a1-97c2-40f0-98ef-362e6591e68b",
   "metadata": {},
   "source": [
    "Let’s also separate the predictors and the labels, since we don’t necessarily want to\n",
    "apply the same transformations to the predictors and the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb81438-58b2-4925-815b-b16b8b497c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = train_set[\"median_house_value\"].copy()\n",
    "test_housing = test_set.drop(\"median_house_value\", axis=1)\n",
    "test_housing_labels = test_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6cda9-1d90-4e15-9c95-3c61f5e59443",
   "metadata": {},
   "source": [
    "Let's replace missing values by the median of that column , that's what we will do with $ total bedrooms $ feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019af19-d2dc-4484-8437-4aaf5f016868",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777addcf-9ccc-477c-9245-d33dc535f2a0",
   "metadata": {},
   "source": [
    "Scikit-Learn provides a handy class to take care of missing values: SimpleImputer.\n",
    "Here is how to use it. First, you need to create a SimpleImputer instance, specifying\n",
    "that you want to replace each attribute’s missing values with the median of that\n",
    "attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68c65e-9779-426b-beb5-5485e2e25676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d2674-9fb4-4a66-a7eb-fb5fb2506559",
   "metadata": {},
   "source": [
    "Since the median can only be computed on numerical attributes, you need to create a\n",
    "copy of the data without the text attribute ocean_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc607b-3ed0-4031-8054-0bb6827a6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "housing_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750eb08-0481-4f81-a01e-e57a37f8bc66",
   "metadata": {},
   "source": [
    "Now you can fit the imputer instance to the training data using the fit() method and the result will be stored in statistics method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084075d-95b4-4284-9a50-14c517309bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(housing_num)\n",
    "housing_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404cb162-a907-462a-9113-39855fcbca62",
   "metadata": {},
   "source": [
    "The imputer has simply computed the median of each attribute and stored the result\n",
    "in its statistics_ instance variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc8051-dcc2-427b-972b-17c1e6f3ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683c5aa5-7f5c-423c-b1ad-ffefbfce2104",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num.median().values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c998d-a8e1-4b03-b44f-3101abf77575",
   "metadata": {},
   "source": [
    "Now you can use this “trained” imputer to transform the training set by replacing\n",
    "missing values with the learned medians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509d7fa-e9b5-4bcc-ba0c-c97d4f58a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d14013-d759-4479-8049-99b02c70b49b",
   "metadata": {},
   "source": [
    "The result is a plain NumPy array containing the transformed features. If you want to\n",
    "put it back into a pandas DataFrame, it’s simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77179ca-33bd-4a6c-9ebb-d9fcf3b05300",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    " index=housing_num.index)\n",
    "housing_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5291a476-d090-448f-977c-f7dca36fba95",
   "metadata": {},
   "source": [
    "# Handling Text and Categorical Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2205dc-a794-4d57-a4a5-4747f6314ea6",
   "metadata": {},
   "source": [
    "Let's visualize some of the ocean_proximity column containing categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c88d2d-3a14-4973-8abb-b17c3a927f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d06dd-ba70-4c9f-be62-11dfffde5164",
   "metadata": {},
   "source": [
    "Let's use ordinal encoding to convert text values to numerical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7925b1-358f-49a4-81f8-29c099740f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1f2c3-3529-4681-8e20-39586faa6aba",
   "metadata": {},
   "source": [
    "You can get the list of categories using the categories_ instance variable. It is a list\n",
    "containing a 1D array of categories for each categorical attribute (in this case, a list\n",
    "containing a single array since there is just one categorical attribute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ade2b-effd-4676-9c8a-31497f0127f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582c94b-24de-4fdd-876a-1b388bcf4e23",
   "metadata": {},
   "source": [
    "One issue with this representation is that ML algorithms will assume that two nearby\n",
    "values are more similar than two distant values. This may be fine in some cases (e.g.,\n",
    "for ordered categories such as “bad,” “average,” “good,” and “excellent”), but it is obvi‐\n",
    "ously not the case for the ocean_proximity column (for example, categories 0 and 4\n",
    "are clearly more similar than categories 0 and 1). To fix this issue, a common solution\n",
    "is to create one binary attribute per category: one attribute equal to 1 when the cate‐\n",
    "gory is “<1H OCEAN” (and 0 otherwise), another attribute equal to 1 when the cate‐\n",
    "gory is “INLAND” (and 0 otherwise), and so on. This is called ** one-hot encoding, **\n",
    "because only one attribute will be equal to 1 (hot), while the others will be 0 (cold).\n",
    "The new attributes are sometimes called dummy attributes. Scikit-Learn provides a\n",
    "OneHotEncoder class to convert categorical values into one-hot vectors:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd5c85-15a3-496d-8521-ebcce129e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c9755-e76f-42f2-9041-7189fd36e966",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed2107-a0b4-4e3c-bd17-51081f03b402",
   "metadata": {},
   "source": [
    "There are two common ways to get all attributes to have the same scale: min-max (normalization)\n",
    "scaling and standardization. for min max , it's simple we substract the min value and divide by the max value all of our example. Whereas standarization first subtracts the mean value (so standardized values \n",
    "always have a zero mean), and then it divides by the standard deviation so that th \n",
    "resulting distribution has unit varian.ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65856f4f-71ec-4e8b-b2fe-ba041f867205",
   "metadata": {},
   "source": [
    "## Transformation Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca773da8-3087-4b41-bde6-7d3a8a9066b8",
   "metadata": {},
   "source": [
    "Pipelines in scikitlearn help us gather all the transofmation we want to apply to the data in the same order . SO let's create a transformation pipeline for our numerical features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fdd42-bc1e-489a-aed0-1c1505d503f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    " ('imputer', SimpleImputer(strategy=\"median\")),\n",
    " ('std_scaler', StandardScaler()),\n",
    " ])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2a2a6-6735-4e2c-8bc3-07a964f8adc9",
   "metadata": {},
   "source": [
    "There is a way to both treat numerical and categorical data in one shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451283c-7947-40ad-a4e4-629377a194de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer ([\n",
    " (\"num\", num_pipeline, num_attribs),\n",
    " (\"cat\", OneHotEncoder(), cat_attribs),\n",
    " ])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "test_prepared = full_pipeline.fit_transform(test_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0d407-7463-44be-899e-652329653b77",
   "metadata": {},
   "source": [
    "## Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bca8f3c-a37c-417d-94b6-a058b143235d",
   "metadata": {},
   "source": [
    "now it's time to select a model to train it on our cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d531cb-1f67-4aa0-8af0-763514775520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e789a895-6ea5-4f0c-9596-bf5d1f9ba8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18634605-ed5f-4a2c-9048-a2319c1f8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216f725-d32a-4eef-8d75-2a213d25c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "housing_predictions = lin_reg.predict(test_prepared)\n",
    "lin_mse = mean_squared_error(test_housing_labels, housing_predictions)\n",
    "lin_r2 = r2_score(test_housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse , lin_mse, lin_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe6771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
